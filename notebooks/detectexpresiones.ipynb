{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuración librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import cv2\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función para cargar la red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carga de la red neuronal convolucional entrenada\n",
    "#retorna el objeto ya instanciado\n",
    "def cargar_CNN():\n",
    "    model=tf.keras.models.load_model(r'data/redneuronal/DRostrosCNN.h5')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carga del clasificador Cascade para detección de rostros\n",
    "def cargar_Cascade():\n",
    "    face_cascade_name = 'data/redneuronal/haarcascade_frontalface_alt.xml'\n",
    "    face_cascade = cv2.CascadeClassifier()\n",
    "    if not face_cascade.load(face_cascade_name):\n",
    "        print('Error al cargar Face Cascade')\n",
    "        exit(0)\n",
    "    return face_cascade"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Función para detectar el área donde se encuentran los rostros "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Esta función retorna una imagen que contiene el rostro captado por la\n",
    "#cámara\n",
    "def detectar_rostro(frame,face_cascade):\n",
    "    faces = face_cascade.detectMultiScale(frame)\n",
    "    if len(faces)!=0:\n",
    "        (x,y,w,h)=faces[0]\n",
    "        return frame[y:y+h,x:x+w]\n",
    "    else:\n",
    "        return frame"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmo\n",
    "### Configuración cámara y carga de las redes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0,cv2.CAP_DSHOW)\n",
    "detector_rostros = cargar_Cascade()\n",
    "red_convolucional = cargar_CNN()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procesamiento imagenes y clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Procesamiento de la imagen\n",
    "ret, frame = cap.read() #Obtención de la imagen de la cámara\n",
    "frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) #Conversión a escala de grises\n",
    "frame = detectar_rostro(frame, detector_rostros) #Detección del rostro\n",
    "frame = cv2.resize(frame, (48,48), interpolation = cv2.INTER_CUBIC) #Rescalamiento a 48x48 pixeles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conversión de las imagenes de matriz a vector\n",
    "x_test = np.array(frame)\n",
    "x_test = np.expand_dims(x_test,axis=0)\n",
    "prediccion = np.argmax(red_convolucional.predict(x_test, verbose=0)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clasificación\n",
    "etiqueta = ''\n",
    "\n",
    "if prediccion == 0:  \n",
    "    etiqueta='Enojo'\n",
    "\n",
    "if prediccion == 1:  \n",
    "    etiqueta='Alegria'\n",
    "\n",
    "if prediccion == 2: \n",
    "    etiqueta='Neutro'\n",
    "\n",
    "if prediccion == 3: \n",
    "    etiqueta='Tristeza'\n",
    "\n",
    "print(etiqueta)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función para la detección de expresiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deteccion_expresiones(cap, detector_rostros, red_convolucional, verbose:bool = False, mostrar_ima:bool = False):\n",
    "    #Procesamiento de la imagen\n",
    "    ret, frame = cap.read() #Obtención de la imagen de la cámara\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) #Conversión a escala de grises\n",
    "    frame = detectar_rostro(frame, detector_rostros) #Detección del rostro\n",
    "    frame_a_mostrar = frame\n",
    "    frame = cv2.resize(frame, (48,48), interpolation = cv2.INTER_CUBIC) #Rescalamiento a 48x48 pixeles\n",
    "\n",
    "    #Conversión de las imagenes de matriz a vector\n",
    "    x_test = np.array(frame)\n",
    "    x_test = np.expand_dims(x_test,axis=0)\n",
    "    prediccion = np.argmax(red_convolucional.predict(x_test, verbose=0)[0][0])\n",
    "\n",
    "    #Clasificación\n",
    "    etiqueta = ''\n",
    "\n",
    "    if prediccion == 0:  \n",
    "        etiqueta='Enojo'\n",
    "\n",
    "    if prediccion == 1:  \n",
    "        etiqueta='Alegria'\n",
    "\n",
    "    if prediccion == 2: \n",
    "        etiqueta='Neutro'\n",
    "\n",
    "    if prediccion == 3: \n",
    "        etiqueta='Tristeza'\n",
    "\n",
    "    if verbose: print(etiqueta)\n",
    "    \n",
    "    if mostrar_ima: cv2.imshow('imagen',frame_a_mostrar)\n",
    "    \n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        raise ValueError(\"Programa Detenido\")\n",
    "\n",
    "    return etiqueta"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
